{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2607ba91",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### LLM Agents with Reinforcement Learning\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc728a",
   "metadata": {},
   "source": [
    "##### Core Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6106c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from typing import List, Dict, Optional, Callable, Tuple\n",
    "\n",
    "# --- Data & Visualization ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")  # Optional: Apply plotting style\n",
    "\n",
    "# --- Display Utilities (Jupyter) ---\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- HTTP & API Interaction ---\n",
    "import requests\n",
    "\n",
    "# --- Utilities ---\n",
    "from pprint import pprint  # Optional: Pretty-print JSON responses\n",
    "\n",
    "# --- Constants for LLM ---\n",
    "OLLAMA_MODEL = \"llama3\"  # Adjust as needed\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2eac5",
   "metadata": {},
   "source": [
    "##### Query LLM Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "386d4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(\n",
    "    prompt: str,\n",
    "    model: str,\n",
    "    api_url: str,\n",
    "    stream: bool = False,\n",
    "    display_markdown: bool = True,\n",
    "    header: Optional[str] = None,\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Query a locally or remotely hosted LLM endpoint and optionally display formatted output in a Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt to send to the LLM.\n",
    "        model (str): The name of the model to use.\n",
    "        api_url (str): The API endpoint URL.\n",
    "        stream (bool): Whether to stream the response.\n",
    "        display_markdown (bool): Whether to display output as Markdown in Jupyter.\n",
    "        header (Optional[str]): Optional header for Markdown display.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The response string (if display_markdown is False), else None.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if stream:\n",
    "            result = \"\"\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    try:\n",
    "                        result += json.loads(line.decode())[\"response\"]\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        else:\n",
    "            result = response.json().get(\"response\", \"\").strip()\n",
    "\n",
    "        if display_markdown:\n",
    "            markdown_text = f\"### {header}\\n\\n{result}\" if header else result\n",
    "            display(Markdown(markdown_text))\n",
    "            return None\n",
    "\n",
    "        return result\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"[LLM ERROR] {e}\"\n",
    "        if display_markdown:\n",
    "            display(Markdown(f\"**LLM Error:** `{e}`\"))\n",
    "            return None\n",
    "        print(error_msg)\n",
    "        return error_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21f3f689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Prisoner's Dilemma in Game Theory\n",
       "\n",
       "The Prisoner's Dilemma is a classic game-theoretic paradox that illustrates the conflict between individual and group rationality. It was first introduced by Merrill Flood and Melvin Dresher in 1950, and later popularized by Albert Tucker.\n",
       "\n",
       "Here's the scenario:\n",
       "\n",
       "Two suspects, A and B, are arrested and interrogated separately by the police about a crime they committed together. Each has two options: to confess (C) or to remain silent (S). The payoffs for each player are as follows:\n",
       "\n",
       "|  | A's Strategy     | B's Strategy      |\n",
       "| --- | --- | --- |\n",
       "| **A** | C (Confess)   | C    | S (Silent)   |\n",
       "| **B** |            | 2, 2        | 3, 0        |\n",
       "|          |            | 0, 3        | 1, 1        |\n",
       "\n",
       "The payoffs are as follows:\n",
       "\n",
       "* If both confess (C, C), they each get a punishment of 2 years in prison.\n",
       "* If one confesses and the other remains silent, the confessor gets a reduced sentence of 1 year, while the silent prisoner gets a harsh sentence of 3 years.\n",
       "* If both remain silent (S, S), they each get a moderate sentence of 1 year.\n",
       "\n",
       "The dilemma arises because each player's rational choice is to defect (confess) regardless of what the other does. This is because the best outcome for each player is to minimize their own punishment by confessing, even if the other player remains silent.\n",
       "\n",
       "However, this creates a problem: both players would rather cooperate and remain silent, but neither can trust the other to do so. As a result, both end up defecting and getting a worse outcome (2 years in prison) than if they had cooperated and remained silent (1 year each).\n",
       "\n",
       "The Prisoner's Dilemma is important in game theory for several reasons:\n",
       "\n",
       "1. **It highlights the tension between individual and group rationality**: The paradox shows that what is rational for an individual may not be rational for a group.\n",
       "2. **It demonstrates the difficulty of cooperation**: The Prisoner's Dilemma illustrates how cooperation can break down when individuals prioritize their own self-interest over the greater good.\n",
       "3. **It has implications for real-world scenarios**: The dilemma has been applied to various fields, such as economics, politics, and biology, to understand issues like international relations, trade agreements, and evolutionary strategies.\n",
       "\n",
       "In summary, the Prisoner's Dilemma is a thought-provoking game that demonstrates how individual rationality can lead to suboptimal outcomes when cooperation is essential. It has far-reaching implications for understanding human behavior, decision-making, and the challenges of achieving collective welfare."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the LLM connection (clean display with Markdown)\n",
    "test_prompt = \"What is the prisoner's dilemma and why is it important in game theory?\"\n",
    "query_llm(\n",
    "    prompt=test_prompt,\n",
    "    model=OLLAMA_MODEL,\n",
    "    api_url=OLLAMA_API_URL,\n",
    "    header=\"Prisoner's Dilemma in Game Theory\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63dcc5e",
   "metadata": {},
   "source": [
    "##### Agent with Deep Reinforcement Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9586d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import Markdown, display\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class GenerativeRLAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        persona: str,\n",
    "        objectives: str,\n",
    "        constraints: str,\n",
    "        strategies: str,\n",
    "        model: str = \"llama3\",\n",
    "        api_url: str = \"http://localhost:11434/api/generate\"\n",
    "    ):\n",
    "        self.persona = self._validate_input(persona, \"Persona\", 600)\n",
    "        self.objectives = self._validate_input(objectives, \"Objectives\", 600)\n",
    "        self.constraints = self._validate_input(constraints, \"Constraints\", 600)\n",
    "        self.strategies = self._validate_input(strategies, \"Strategies\", 600)\n",
    "        self.model = model\n",
    "        self.api_url = api_url\n",
    "\n",
    "    def _validate_input(self, value: str, field: str, max_len: int) -> str:\n",
    "        if not isinstance(value, str) or not (0 < len(value) <= max_len):\n",
    "            raise ValueError(f\"{field} must be a non-empty string with max {max_len} characters.\")\n",
    "        return value.strip()\n",
    "\n",
    "    def _call_llm(self, prompt: str) -> str:\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(self.api_url, json=payload, timeout=60)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"response\", \"\").strip() or \"[No response]\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return f\"**LLM ERROR:** `{e}`\"\n",
    "\n",
    "    def process_input(self, input_text: str) -> str:\n",
    "        input_text = self._validate_input(input_text, \"Input Text\", 300)\n",
    "\n",
    "        prompt = textwrap.dedent(f\"\"\"\n",
    "        You are an intelligent reinforcement learning agent operating under the following profile:\n",
    "\n",
    "        Persona: {self.persona}\n",
    "        Objectives: {self.objectives}\n",
    "        Constraints: {self.constraints}\n",
    "        Strategies: {self.strategies}\n",
    "\n",
    "        The user has provided the following input:\n",
    "        \"{input_text}\"\n",
    "\n",
    "        Perform the following steps, and return your response using Markdown formatting:\n",
    "\n",
    "        ### STEP 1 - Thinking\n",
    "        Briefly explain what you understand from the input.\n",
    "\n",
    "        ### STEP 2 - Unbiased Thinking\n",
    "        Independently reflect on the situation without applying your persona.\n",
    "\n",
    "        ### STEP 3 - Agent Response\n",
    "        Now apply your persona, objectives, constraints, and strategies to give your optimal action.\n",
    "        Respond with a clear, actionable message between **10 and 300 characters**.\n",
    "        Then, summarize that response in a single sentence of **10 to 300 characters**, prefixed with:\n",
    "        \"**Agent Summary:**\"\n",
    "        \"\"\")\n",
    "\n",
    "        result = self._call_llm(prompt)\n",
    "        display(Markdown(result))\n",
    "\n",
    "        # Extract and validate summary\n",
    "        summary = \"\"\n",
    "        for line in result.splitlines():\n",
    "            if line.strip().startswith(\"**Agent Summary:**\"):\n",
    "                summary = line.split(\"**Agent Summary:**\", 1)[-1].strip()\n",
    "                break\n",
    "\n",
    "        if not (10 <= len(summary) <= 300):\n",
    "            summary = \"**Agent Summary:** [ERROR] Summary not within 10–300 characters.\"\n",
    "\n",
    "        display(Markdown(f\"---\\n\\n{summary}\"))\n",
    "        return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915673f",
   "metadata": {},
   "source": [
    "[TESTING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e86d9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### STEP 1 - Thinking\n",
       "The input suggests market volatility following the Federal Reserve's interest rate decision. This could imply uncertainty or surprise from the Fed's action.\n",
       "\n",
       "### STEP 2 - Unbiased Thinking\n",
       "Market fluctuations are natural after significant economic events like a Fed interest rate decision. It's essential to assess the potential impact on asset classes and reevaluate the portfolio in this environment.\n",
       "\n",
       "### STEP 3 - Agent Response\n",
       "**Rebalance into stable sectors and increase cash exposure by 5% to minimize potential drawdowns while waiting for market clarity.**\n",
       "\n",
       "**Agent Summary:** Increase cash allocation by 5% to mitigate potential losses and wait for market stabilization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "Increase cash allocation by 5% to mitigate potential losses and wait for market stabilization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Increase cash allocation by 5% to mitigate potential losses and wait for market stabilization.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investor_agent = GenerativeRLAgent(\n",
    "    persona=\"Cautious AI investor focused on long-term portfolio preservation.\",\n",
    "    objectives=\"Minimize drawdowns while capturing upside in low-volatility assets.\",\n",
    "    constraints=\"Avoid leveraged instruments and high-beta tech stocks.\",\n",
    "    strategies=\"Rebalance into stable sectors during uncertainty; increase cash exposure.\",\n",
    "    model=\"llama3\",\n",
    "    api_url=\"http://localhost:11434/api/generate\"\n",
    ")\n",
    "\n",
    "\n",
    "investor_agent.process_input(\"Markets are swinging wildly after the Fed interest rate decision.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
